{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 7, "column": 0}, "map": {"version":3,"sources":["file:///Users/aryan/projects/personalwebsite/src/data/blogs.ts"],"sourcesContent":["export type BlogPost = {\n  id: string;\n  title: string;\n  slug: string;\n  date: string;\n  summary: string;\n  content: string;\n  coverImage?: string;\n  isProjectBlog: boolean;\n  projectId?: number;\n  tags: string[];\n};\n\nexport const blogPosts: BlogPost[] = [\n  {\n    id: \"1\",\n    title: \"Hyperloo: Building a Knowledge Graph for University Courses\",\n    slug: \"hyperloo-project-blog\",\n    date: \"2025-04-23\",\n    summary: \"How I built an algorithmically generated knowledge graph for UWaterloo programs and courses\",\n    content: `\nHyperloo is a knowledge graph that maps out all topics, courses, and degrees at the University of Waterloo. Traditional degree structures tend to be abstract, making it difficult to visualize the interconnected nature of knowledge. I wanted to change that. What if you could represent an entire degree visually - showing how concepts interlink and build on one another? That question led me deep into knowledge graphs, which I found incredibly powerful as a tool for structuring and exploring complex domains.\n\n## Why Knowledge Graphs?\n\nConcepts are inherently nested objects. Take nuclear physics - understanding the entire field seems daunting. But break it down, and it's really just a collection of interconnected subtopics. Each of those subtopics can be further divided, creating a layered structure that makes even the most complex subjects feel approachable. Knowledge graphs embody this philosophy: no topic is truly out of reach if broken down correctly. Seeing how subjects connect makes learning more intuitive, empowering students to explore topics they once thought were beyond them.\n\nOne of my key inspirations was the Socratica graph matching from the 2023 Socratica Symposium. As graph tooling continues to improve, I believe we'll see knowledge graphs become a standard way to represent and navigate information.\n\n## Building Hyperloo\n\nCreating Hyperloo was a long and technically challenging process. The first step was data collection: scraping every Waterloo syllabus to form a base knowledge corpus. We used Selenium to automate the scraping, parsing programs, courses, and subtopics iteratively. This required multiple browser automation scripts to extract structured data from unstructured web pages. The process was labor-intensive, but necessary.\n\nOnce we had a structured corpus, the next challenge was transforming raw syllabus text into meaningful graph data. We trained a custom NLP model using SpaCy to extract key information. The NLP pipeline was relatively simple - a classification model trained with labeled examples to recognize important syllabus components. After multiple iterations, we achieved ~92% accuracy, which was sufficient for our needs. The model's purpose wasn't perfect precision but rather rough approximation to filter syllabus content into useful knowledge nodes.\n\nWith the extracted information, we structured the data into a nested JSON format that could be easily visualized as a graph. To generate these structured JSON objects, we used OpenAI's Batch API, processing large volumes of text and distilling them into a structured hierarchy. The result was a massive JSON-L file representing Waterloo's academic knowledge as a network of interconnected topics.\n\nFinally, we built the front end using React, leveraging the GraphForce component to render the knowledge graph. While some customization was required to optimize the visualization, the hardest part of the project was the data transformation itself - getting from raw syllabi to structured knowledge nodes.\n\n## Impact and Utility\n\nHyperloo has already gained traction. After sharing it on LinkedIn and Twitter, it received over 250 likes on LinkedIn and 100+ on Twitter. More importantly, it was bookmarked 17 times on Twitter - an indicator that people actually intend to use it as a reference.\n\nFor Waterloo students, the utility is clear. Hyperloo provides a structured, visual way to explore degree programs, understand prerequisite relationships, and dive into any topic of interest. Even if only a few dozen students actively use it, that's a meaningful outcome for me.\n\nBut the implications go beyond Waterloo. With Hyperloo, anyone, anywhere in the world, can effectively trace the structure of a Waterloo degree and use it as a self-learning roadmap. Even though it's not a complete curriculum, the ability to map out an entire field and navigate it freely is incredibly powerful. In theory, a student in a third world nation or any remote region could use Hyperloo, coupled with Perplexity AI and other online resources, to pursue an entire degree's worth of knowledge for free.\n\n## What's Next?\n\nBefore starting any project, I ask myself: if I were to disappear tomorrow, what would I leave behind? Hyperloo is one of those projects that feels genuinely useful - not just to me, but to the broader world. If it grows, it could be a foundational resource for structured, open-access education. That's the kind of impact worth building for.\n\nCheck out the production version of Hyperloo [here](https://tumph.github.io/hyperlooprod/).\n\n\n    `,\n    coverImage: \"/hyperloo.png\",\n    isProjectBlog: true,\n    projectId: 1,\n    tags: [\"NLP\", \"Web Scraping\", \"Knowledge Graph\", \"Next.js\"]\n  },\n  {\n    id: \"2\",\n    title: \"Doledesk: Automating Substitute Teacher Scheduling\",\n    slug: \"doledesk-project-blog\",\n    date: \"2023-03-15\",\n    summary: \"How I built a system to automate substitute teacher scheduling\",\n    content: `\nIn 2023, I started looking into inefficiencies in school operations - areas where automation could replace tedious, repetitive processes. Automation was becoming increasingly practical, and I wanted to build something with real impact. That led me to a conversation with my high school's vice principal. I asked a simple question: ‚ÄúWhat are the most time-consuming tasks you deal with daily?‚Äù\n\nThe answer was clear: substitute teacher scheduling. Every morning, administrators scrambled to check which teachers were absent, cross-referencing a massive spreadsheet to manually assign substitutes. It was an inefficient, error-prone process - one that was ripe for automation. That insight led me to build Doledesk, a system designed to fully automate substitute teacher scheduling using a rules-based algorithm.\n\n## The Complexity of Scheduling\n\nAt first, scheduling substitutes seemed like a straightforward problem - identify absent teachers and match them with available subs. But the deeper I went, the more complexity I uncovered. Several constraints made this a non-trivial problem:\n\n- Legal Compliance: Many school districts have strict labor laws. For example, a teacher can't work more than three consecutive periods without a break.\n\n- Subject Matching: Not all substitutes can teach every subject. A math teacher shouldn't be assigned to an English class.\n\n- Multi-Layered Dependencies: If one substitute isn't available, the entire schedule may need to be reshuffled dynamically.\n\n- Data Privacy Restrictions: Storing teacher data required careful adherence to K-12 privacy regulations, meaning traditional database solutions weren't viable.\n\nThese constraints required a robust, flexible system capable of handling real-world edge cases while optimizing for efficiency.\n\n## Building Doledesk\n\nThe core of Doledesk was a backend system built with Java and JavaScript, designed to process teacher absences and dynamically assign substitutes. Here's how it worked:\n\n- Data Input Pipeline: Each morning, a fresh list of absent teachers was fed into the system. Since storing persistent data wasn't an option due to privacy regulations, all scheduling had to happen in real-time.\n\n- Algorithmic Matching: The backend used a constraint-satisfaction algorithm to assign substitutes based on availability, subject expertise, and legal guidelines. If an optimal match wasn't found, the algorithm recursively adjusted placements.\n\n- Automated Notifications: Once schedules were finalized, the system sent out automated email notifications to substitutes and teachers.\n\n- Failsafe Mechanisms: If any substitute declined their assignment, the system reran the matching algorithm to fill gaps dynamically.\n\nFor the UI, I opted for Bubble, a no-code editor, to accelerate frontend development. This allowed me to quickly iterate on the UI and get a working product.\n\n## Deployment and Impact\n\nOnce Doledesk was live, my school used it for a month. The result? Administrators who previously spent hours manually assigning substitutes were now completing the process in minutes. What used to be a chaotic, last-minute scramble was now a structured, automated workflow.\n\nWhile this project started as an experiment, it quickly became something more - proof that automation can significantly reduce administrative overhead in education. Doledesk wasn't just about saving time; it was about ensuring that students always had the right teachers in place, improving the overall classroom experience.\n\n## What's Next?\n\nDoledesk validated an important idea: many outdated, manual processes in education can be automated with the right approach. Looking forward, I see opportunities to expand this concept beyond substitute scheduling - perhaps into broader school operations or even district-wide automation tools.\n    `,\n    coverImage: \"/doledesk.png\",\n    isProjectBlog: true,\n    projectId: 2,\n    tags: [\"Java\", \"JavaScript\", \"Bubble\"]\n  },\n  {\n    id: \"3\",\n    title: \"Pare: Summarizing Resumes on Any ATS\",\n    slug: \"pare-project-blog\",\n    date: \"2024-09-3\",\n    summary: \"How I built a browser extension to summarize resumes on any ATS\",\n    content: `\n## The Hiring Challenge\n\nIn 2024, I embarked on a project to tackle inefficiencies in the recruiting industry, a journey inspired by my experience with the Waterloo Co-op program. My first co-op was at an AI company called ada, and while the opportunity was exciting, the hiring process itself was frustratingly arduous. Securing the position required significant effort, and the lack of feedback or even rejection emails while applying to other jobs left me feeling like my resume was getting lost in the void.\n\nAt first, I blamed recruiters, assuming they weren't reviewing resumes properly. However, after speaking with several recruiters, I realized the problem wasn't them - it was the sheer volume of applications they had to process daily. Some recruiters I spoke to had thousands of resumes to sift through, often spending only 5-10 seconds per resume. Given these constraints, it became clear that recruiters simply didn't have the bandwidth to provide personalized responses to every applicant.\n\nThis insight led me to ask: Could technology streamline this process and help recruiters make better decisions, faster? That's when I built Pare, a resume summarization tool designed to make the recruiting process more efficient.\n\n## Introducing Pare: A Resume Summarizer for ATS Platforms\n\nPare is a browser extension that integrates with any Applicant Tracking System (ATS) to help recruiters process resumes faster. For those unfamiliar, an ATS is the software recruiters use to track applicants, manage job postings, and oversee hiring pipelines - it's like CRM software but tailored for recruiting.\n\nSince recruiters only have a few seconds to assess a resume, I saw an opportunity to reduce cognitive load by providing structured, AI-generated summaries. The goal was simple: help recruiters get to the essence of a candidate's experience in a fraction of the time.\n\n## The Technical Approach\n\nBuilding Pare came with significant technical challenges. The primary complexity lay in making the extension work seamlessly across multiple ATS platforms, each with its own data structures and UI implementations. Some ATS platforms rely on React components, others use HTML pop-ups, and some simply display plain text.\n\nHere's how Pare works:\n\n- Resume Extraction: Pare uses PDF.js to extract the text from resumes displayed in ATS platforms.\n\n- AI-Powered Summarization: The extracted resume text is then fed into OpenAI's GPT model with structured prompting to generate a concise, recruiter-friendly summary.\n\n- Dynamic Integration: The extension identifies different ATS architectures and adapts accordingly to display the summarized resume in the appropriate section of the UI.\n\n## Overcoming Edge Cases\n\nA key challenge in developing Pare was ensuring its functionality across different ATS platforms. Some ATS systems store resume data in embedded JavaScript objects, while others use dynamically generated iframes. To address these variations, Pare includes:\n\n- DOM Inspection and Adaptation: The extension dynamically detects how the ATS renders resumes and adapts its extraction process accordingly.\n\n- Asynchronous Handling: Since ATS platforms load data asynchronously, Pare waits for DOM elements to fully render before extracting content, preventing errors from incomplete data.\n\n- Cross-Origin Requests: Some ATS platforms restrict direct access to resume content, requiring workarounds like injecting scripts into the page context to retrieve the necessary data.\n\n## Adoption and Impact\n\nSince launching Pare, several recruiters - many of whom I connected with during the development process - have started using it. A few of my friends running startups with high hiring volumes have also adopted it to streamline their recruiting workflows.\n\nThe extension is available on GitHub, where users can configure it with their own OpenAI API key and install it as an unpacked Chrome extension via Developer Tools. By reducing the time recruiters spend reading resumes, Pare helps them focus on identifying the best candidates rather than drowning in an overwhelming sea of applications.\n\n## What's Next?\n\nPare is just the beginning. There are still many inefficiencies in the hiring process that can be optimized with AI-driven tools. Future iterations of Pare could incorporate:\n\n- Customizable Summarization Styles: Allowing recruiters to tweak summary formats based on industry-specific needs.\n\n- Multi-Resume Comparisons: Automatically highlighting key differentiators between candidates.\n\n- Integration with More ATS Platforms: Expanding native support for widely used recruiting systems.\n\nAt its core, Pare is about making hiring more efficient - both for recruiters and job seekers. By leveraging AI to handle tedious, high-volume tasks, recruiters can spend more time on what truly matters: connecting great candidates with great opportunities.\n    `,\n    coverImage: \"/pare.png\",\n    isProjectBlog: true,\n    projectId: 3,\n    tags: [\"JavaScript\", \"HTML/CSS\", \"Git\", \"PDF.js\"]\n  },\n  {\n    id: \"4\",\n    title: \"SAI Microjet: Optimizing Sulfur Ratios for Geoengineering\",\n    slug: \"sai-microjet-project-blog\",\n    date: \"2022-07-09\",\n    summary: \"Developing a hardware rig and firmware system for a microjet engine to test optimal sulfur ratios for stratospheric aerosol injection.\",\n    content: `\n## A Climate Engineering Experiment\n\nClimate change is one of the most pressing challenges of our time. At its core, it is an energy problem - greenhouse gases trap more solar radiation in the Earth's atmosphere, increasing surface temperatures.\n\nIf you think about climate change from a physics perspective - Earth is essentially a self contained system (all the energy that arrives on Earth from the sun gets dispersed in some way or form - energy cannot be created or destroyed!) and so a thicker atmosphere with higher PPMs of greenhouse gases that trap energy more effectively would lead to more of that energy being dispersed as heat in the atmosphere instead of staying as radiation being reflected back into space. \n\nCurrent efforts to mitigate climate change generally fall into two categories: reducing carbon emissions (by transitioning to renewable energy) and removing carbon already in the atmosphere (through carbon capture technologies). However, this ignores the fact that from a physics perspective, if you want to reduce the energy trapped in a system - you could increase permabilility of the system so less energy is trapped (current methods) - but you could also just prevent that energy from reaching the system in the first place.\n\nGeoengineering strategies aim to reduce the amount of solar radiation reaching Earth. Among the various proposals - such as placing giant mirrors in space or brightening marine clouds - one of the most promising and realistic methods (not as pie in the sky as the other ones) is stratospheric aerosol injection (SAI). This technique involves releasing small aerosol particles, such as sulfur compounds, into the stratosphere to reflect sunlight and cool the planet, similar to how volcanic eruptions impact global temperatures. The reason this is the most realistic is this has actually happened naturally before - A historical example of this effect was the 1991 eruption of Mount Pinatubo, which led to a temporary global cooling of 1-2 degrees Celsius.\n\nEven if you reduce the amount of sunlight reaching Earth by 1-2%, you would completely negate the 2-3 centuries of anthropogenic climate change we have experienced up till today. Isn't that crazy? And the effect to plant fauna would be negligible - would you really be thirsty if your glass of water had 1% less water in it?\n\n## A Practical Approach: Sulfur Injection via Jet Engine Fuel\n\nRather than deploying a specialized fleet of aircraft carrying sulfur dioxide tanks for stratospheric aerosol injection (as current research is doing), my project explored a more efficient approach: integrating sulfur directly into jet fuel. This concept allows aircraft to release sulfur precursors passively as they fly, eliminating the need for dedicated spraying equipment.\n\nMy research, conducted with Andrew Lockley from the University College London, began with a conceptual analysis of this approach. However, to validate the feasibility of sulfur-infused jet fuel, I moved beyond theory into practical experimentation.\n\n## Testing with a Microjet Engine\n\nTo test the concept, I acquired a microjet engine - a scaled-down jet engine that operates on the same physical principles as full-scale aircraft turbines. Instead of experimenting on a multimillion-dollar Rolls-Royce engine, a microjet provided a cost-effective, low-risk way to evaluate fuel modifications.\n\n## Experiment Design\n\nThe experiment involved three key components:\n\n- Engine Modification & Sensor Integration:\n\nThe microjet engine had built-in safety mechanisms that prevented it from running when detecting foreign substances in the fuel. I modified the firmware to bypass these restrictions and allow sulfur-infused fuel to be burned.\n\n- Measuring Sulfur Dioxide Emissions:\n\nA sulfur dioxide sensor was placed in a copper tube behind the engine to monitor emissions and quantify how much sulfur was successfully converted from fuel to atmospheric aerosol precursors.\n\n- Thrust Performance Analysis:\n\nThe engine was mounted on a force dynamo, which measured changes in thrust output. Since fuel composition can impact engine efficiency, it was important to determine if adding sulfur affected performance.\n\n## Findings\n\nThe results confirmed the fundamental hypothesis: adding sulfur to the fuel led to increased sulfur dioxide emissions, making this a viable method for stratospheric aerosol injection. However, an interesting tradeoff emerged:\n\n- Small amounts of sulfur improved engine performance slightly while still generating the desired emissions.\n\n- Excessive sulfur content led to a decline in thrust output, which could make it difficult for an aircraft to reach the stratosphere.\n\nThis revealed a crucial optimization problem - balancing sulfur levels to maximize climate impact while maintaining efficient aircraft performance.\n\n## Implications & Future Research\n\nWhile SAI remains a high-risk, last-resort solution for climate change, my project demonstrated that passively integrating sulfur into jet fuel is a feasible approach to geoengineering. It eliminates the need for dedicated spraying infrastructure and aligns with existing aviation technology.\n\nOf course, serious risks remain. Any large-scale geoengineering effort requires extensive environmental modeling and international collaboration. History has shown that manipulating natural systems can have unintended consequences. Therefore, SAI should not be seen as an immediate solution, but rather as a potential tool for the future - one that could be deployed if climate conditions become dire enough to warrant it.\n\nAny time humans have messed with nature, we have had unintended consequences. Stories of humans releasing a certain species into the wild, and it becoming an invasive species, are a dime a dozen. And that's in a relatively simple system like an ecosystem. The atmosphere is a much more complex system, and so the potential for unintended consequences is much higher.\n\nHowever, I still think the climate threat, if left unchecked, is so severe that we should be exploring all options. As a last resort option to governments in the latter half of the century, SAI could be a crucial tool to save humanity.\n\nThis project was an exciting step toward understanding practical climate intervention methods. The next phase could involve further optimizing the fuel mixture, testing on larger jet engines, and assessing the long-term atmospheric impacts of such an approach. While geoengineering is not a silver bullet, it may one day provide a crucial buffer as humanity transitions to a sustainable energy future.\n\n    `,\n    coverImage: \"/geoeng.jpg\",\n    isProjectBlog: true,\n    projectId: 4,\n    tags: [\"Python\", \"Firmware\", \"Mechanical Design\", \"CAD\"]\n  },\n  {\n    id: \"5\",\n    title: \"reverseATS: find the most relevant job postings\",\n    slug: \"reverseats-project-blog\",\n    date: \"2025-03-19\",\n    summary: \"How I built a tool to find the most relevant job postings for a given resume\",\n    content: `\n    Finding a co-op is hard. Finding the right co-op is even harder.\n\nAs a University of Waterloo student, I've spent countless hours inside WaterlooWorks - our school's co-op job portal - scrolling through thousands of postings, unsure which ones were actually worth my time. Some jobs felt like a shot in the dark. Others looked promising but yielded no response. The whole process felt like I was playing darts blindfolded.\n\nIt got me thinking: recruiters use Applicant Tracking Systems (ATS) to screen candidates before they ever see a resume. These systems do keyword matching, similarity scoring, and automatic filtering. But as applicants, we're flying blind. We don't get to see how well we match a posting. We don't get a score. We don't even get feedback.\n\nSo I decided to flip the system.\n\n## Introducing ReverseATS\n\nReverseATS is a Chrome extension that analyzes every job listing on WaterlooWorks and ranks them based on how closely they match your resume. It's a reverse-engineered ATS - one that works for students instead of recruiters.\n\nUpload your resume, visit any page on WaterlooWorks, and the extension quietly scans the jobs, compares them against your experience using keyword similarity, and injects a match score next to each posting. No buttons. No clutter. Just seamless signal in a sea of noise.\n\n## Why I Built It\n\nThe core problem I wanted to solve was fit - helping students answer the question: What jobs am I most likely to get?\nIt's not about filtering only the ‚Äúbest‚Äù jobs. It's about visibility. If I knew I was a 92% match for Job A but only a 31% match for Job B, I could make better decisions. I could prioritize jobs I had a shot at. I could tailor my applications more effectively. I could stop wasting time.\n\nReverseATS brings that insight to the surface. It makes the job hunt feel less like roulette and more like chess.\n\n## The Technical Journey (and a Mid-Project Meltdown)\n\nReverseATS started as a simple scraping tool. WaterlooWorks used to have predictable, REST-style URLs and static HTML content. I used Python, BeautifulSoup, and a bunch of requests logic to pull job descriptions and analyze them. It was crude but effective.\n\nThen - disaster.\n\nAbout 15 days into development, just as I was wrapping up, WaterlooWorks pushed a full UI redesign. The entire front-end architecture changed. No more simple HTML. No more direct URLs. Instead, job data was now fetched through a hidden API gated by dynamically generated action tokens.\n\nI had to reverse-engineer their new system. This meant:\n\t‚Ä¢\tDigging into their front-end JavaScript bundle\n\t‚Ä¢\tLocating the function responsible for generating the token\n\t‚Ä¢\tParsing obfuscated API calls to understand how requests were signed\n\t‚Ä¢\tExtracting session cookies and mimicking the browser's authenticated state\n\nIn short, it went from a weekend project to a deep-dive into front-end forensics.\n\nEventually, I rebuilt the extension from scratch. This time, instead of HTML scraping, ReverseATS:\n\t1.\tAuthenticates via the user's browser session (grabbing cookies and tokens after login)\n\t2.\tFetches job listings in batches using WaterlooWorks' hidden API\n\t3.\tParses job descriptions and metadata\n\t4.\tApplies a keyword similarity algorithm between your resume and each job\n\t5.\tInjects match scores directly into the UI - no extra clicks, no context switching\n\nAll of it happens live, on the page you're already on.\n\n## Why It Matters\n\nIf you're a Waterloo student, you've probably felt the fatigue of applying to dozens of jobs with no clear strategy. ReverseATS gives you a compass. It doesn't guarantee a job - but it does help you navigate smarter.\n\nMy hope is that it saves students time, reduces stress, and helps people apply more strategically. The co-op system has its challenges, but that doesn't mean we have to go in blind.\n\n## What's Next?\n\nThere are a lot of potential improvements: resume parsing from PDF, smarter similarity metrics, a dashboard for tracking matches over time, maybe even automated cover letter generation based on matched keywords.\n\nBut for now, I'm just excited to get this into the hands of other students.\n\nIf you want to try ReverseATS, you can download it [here](https://chromewebstore.google.com/detail/ReverseATS%20Job%20Matcher/ipkldjngbilnepdikdjmhjhfagbjllnj).\n    `,\n    coverImage: \"/reverseats.png\",\n    isProjectBlog: true,\n    projectId: 5,\n    tags: [\"JavaScript\", \"Python\", \"BeautifulSoup\", \"Chrome Extension\"]\n  },\n  {\n    id: \"6\",\n    title: \"chatUW: A Chatbot Trained on Waterloo Student Wisdom\",\n    slug: \"chatuw-project-blog\",\n    date: \"2025-04-05\",\n    summary: \"How I built a RAG chatbot for the University of Waterloo\",\n    content: `\n\nIf you've spent more than five minutes in any University of Waterloo Discord server, Reddit thread, or group chat, you know one thing's for sure: Waterloo students love writing guides.\n\nThere are guides for everything - co-op, surviving first year, U.S. immigration, prof rankings, housing, resumes, entrepreneurship, food, even memes. The sheer volume is honestly impressive.\n\nBut here's the problem: most of them get lost in the noise.\n\nThey're buried in outdated Google Docs, scattered across subreddits, or sitting idle in random Notion pages. New students never find them. Older students forget about them. And most of the content, while incredibly useful, ends up underutilized.\n\nThat got me thinking:\nWhat if you could access all that wisdom instantly?\nWhat if there was a chatbot trained on all those student-made guides - a single place you could go to ask anything about student life at Waterloo?\n\n## Introducing chatUW\n\nchatUW is a RAG-based (Retrieval-Augmented Generation) chatbot trained on publicly available Waterloo student guides. It combines everything from co-op and U.S. visa guides to restaurant recommendations and housing tips into one seamless conversational interface.\n\nIt's basically the student version of ChatGPT - but trained on Waterloo-specific life advice, experience, and resources.\n\nYou can ask it questions like:\n\t‚Ä¢\t‚ÄúWhat's the process for getting a co-op in the U.S.?‚Äù\n\t‚Ä¢\t‚ÄúWhere are some cheap places to eat around campus?‚Äù\n\t‚Ä¢\t‚ÄúWhat are some tips for first-year CS students?‚Äù\n\t‚Ä¢\t‚ÄúHow do I deal with terrible landlords in Waterloo?‚Äù\n\t‚Ä¢\t‚ÄúWhat's the difference between Stream 4 and Stream 8?‚Äù\n\nAnd it'll give you helpful, informed answers based on real guides made by real students.\n\n## Why I Built It\n\nThere was no shortage of content. What was missing was accessibility. The problem wasn't that students weren't sharing knowledge - it was that their knowledge wasn't discoverable or usable at scale.\n\nWe have an informal search engine already - asking upper-years in Discord servers, or sifting through Reddit threads. But that process is inefficient. You might ask a question and get 10 conflicting answers. Or worse, no response at all.\n\nchatUW is meant to be the always-on version of that. It's the ‚Äústudent who's been here for five years and has seen it all‚Äù - just in chatbot form.\n\n## What's Under the Hood\n\nThe stack is pretty standard for a RAG LLM app:\n\t‚Ä¢\tFrontend: Built with Next.js\n\t‚Ä¢\tSecurity: Google reCAPTCHA to prevent abuse\n\t‚Ä¢\tVector Store: Pinecone for fast, scalable embedding search\n\t‚Ä¢\tLLM: OpenAI GPT API\n\t‚Ä¢\tRetrieval: LangChain-powered RAG pipeline to fetch relevant student guide chunks based on your query\n\nThe knowledge base was built by scraping and parsing publicly available guides, including survival guides, co-op advice docs, immigration FAQs, and more. Everything included is open-source or explicitly shared by students - nothing proprietary or copyrighted by the university itself.\n\n## Why It Matters\n\nWaterloo can be overwhelming. The systems are complex, the processes are confusing, and no two students take the same path. But there's a ton of collective wisdom floating around - it just needed a place to live.\n\nchatUW gives students an accessible, conversational way to tap into that collective knowledge. Whether you're new to campus or about to graduate, it's designed to help you navigate student life smarter and faster.\n\n## What's Next?\n\nI'm planning to:\n\t‚Ä¢\tAdd document sources so users can trace where answers came from\n\t‚Ä¢\tAllow uploading of your own guide to contribute to the corpus\n\t‚Ä¢\tIntegrate better UI/UX features to make chatUW feel more like a real student peer than just another bot\n\nThis started as a small side project, but it's quickly becoming something I wish I had when I started at Waterloo.\n\nIf you want to try chatUW or contribute to the guide corpus, reach out - I'd love to chat.\n    `,\n    coverImage: \"/chatuw.png\",\n    isProjectBlog: true,\n    projectId: 6,\n    tags: [\"Pinecone\", \"OpenAI\", \"Next.js\"]\n  },\n{\n  id: \"7\",\n  title: \"uwOS: a Launchpad for Waterloo Students\",\n  slug: \"uwos-project-blog\",\n  date: \"2025-10-15\",\n  summary: \"How I built a macOS-style ‚Äústudent operating system‚Äù that pulls the best UWaterloo tools into one place\",\n  content: `\n\nAt Waterloo there are dozens of genuinely useful tools, but they live across scattered sites, Discord messages, spreadsheets, and browser bookmarks. Each task starts with a hunt. I wanted one home screen that surfaces the most useful student-built, community-built, and university-built tools with zero hunting. That became **uwOS**.\n\nuwOS looks and feels like macOS Launchpad, but for student life. It is a clean grid of tiles with clear categories, instant open, and keyboard-first navigation. You hit one key, you are inside the thing you need. That is it.\n\n\n## What is inside\n\n**Academic**\n- **UW Flow** - course and professor reviews: <https://uwflow.com>\n- **Semesters.ca** - academic planner: <https://semesters.ca>\n- **chatUW** - RAG assistant trained on real upper-year advice\n\n**Campus**\n- **Waterloo Underground Tunnel Map** - get around fast\n- **Spots** - find study spaces on campus\n\n**Transportation**\n- **GRT Transit** - transit updates for Waterloo\n\n**Community**\n- **Waterloo Reddit** - see what the community is talking about\n\n**Productivity**\n- **Perplexity** - quick research and answers\n- **Chrome** - jump straight to the web\n- **reverseATS** - matches you to WaterlooWorks jobs\n\n**Lifestyle**\n- **Waterloo Weather** - plan your day\n- **CupboardCuisine** - AI recipe planner: <https://cupboardcuisine.ai>\n- **Workout.lol** - AI workout planner: <https://workout.lol>\n\n**Tech**\n- **Hyperloo** - knowledge base of programs, majors, and courses\n- **Watguessr** - Waterloo campus GeoGuessr: <https://watguessr.io>\n\nSome of these apps are mine, some were built by other students, and some come from companies or UW. The point is one home and zero friction.\n\n\n## Why a Launchpad\n\nI like projects that reduce friction. Hyperloo mapped the knowledge space for degrees. reverseATS surfaced fit for job searches. uwOS is in the same family, but focused on daily life. Instead of remembering ten URLs or digging through old chats for a link, I want one surface that launches what matters. Familiarity helps, so I borrowed the Launchpad mental model that many students already use every day.\n\n\n## Building uwOS\n\n**Design language**\n- Familiar on purpose. A simple dark canvas, rounded tiles, crisp icons, and readable labels that work on phone and desktop.\n- Motion kept minimal so focus stays on the tools, not the chrome.\n\n**Architecture**\n- **Web first** - Next.js and React with Tailwind for styling. Deployed on Vercel for fast static delivery.\n- **Tile registry** - a single JSON registry defines every app: name, icon, category, URL, and optional launch behavior. Adding a tile is one entry, then done.\n- **Search and keyboard** - type to filter, arrow keys to move, Enter to launch. No learning curve.\n- **Electron wrapper** - wrapped with Electron so uwOS can live as a desktop app. Electron Forge handles packaging.\n\n**Implementation details I enjoyed**\n- A small Node script exports tile icons at multiple sizes so the grid stays crisp on macOS and Linux.\n- Packaging surfaced a funny roadblock: a missing DMG background image that threw an ENOENT error in a macOS build. One image later, green checks across the board.\n- Accessibility matters. Tiles support focus states and labels so fast keyboard use is the default, not an afterthought.\n\n**What it is not**\n- uwOS is not another portal or tracker. It is a launcher. It opens useful things fast and gets out of the way.\n\n## Utility\n\nIf you are a first year, uwOS lowers the cost of discovering the campus toolkit. If you are deep in co-op season, it becomes a faster jump into the tools you already use every day. Even small time savings, repeated daily, compound over a term.\n\n\n## What is next\n\n- **Open submissions** - a simple contribution flow so any student can add a tile with one JSON entry.\n- **Personalization** - pin and reorder tiles, hide what you do not use, save presets by program or year.\n- **Smart groups** - dynamic sections like Today that surface weather, transit, and upcoming deadlines.\n- **Desktop builds** - fuller Electron packaging for macOS, then Windows and Linux.\n- **Tiny helpers** - lightweight badges for live transit alerts or current weather without bloating the app.\n\nIf you have ideas, or you built a tool that helps Waterloo students, I want to hear from you.\n\n\n## Try it\n\nLive here: **<https://uwos.vercel.app>**\n\nIf you want something added, or you are building a Waterloo tool, message me and I will make room for it. The goal is simple: one home, zero friction.\n\n\n## Why this matters to me\n\nBefore starting any project, I ask a simple question: if I disappeared tomorrow, would this still help someone. uwOS clears that bar for me. It reduces everyday friction, and it gives student-built tools a front door that is easy to find.\n  `,\n  coverImage: \"/uwos.png\",\n  isProjectBlog: true,\n  projectId: 7,\n  tags: [\"Next.js\", \"React\", \"Tailwind\", \"Electron\", \"Student Productivity\", \"Electron Forge\"]\n  },\n  {\n    id: \"8\",\n    title: \"Pikachu: a Pair Programming Agent\",\n    slug: \"pikachu-project-blog\",\n    date: \"2025-09-28\",\n    summary: \"How we built a real-time, voice and text enabled pair programming agent and won a hackathon\",\n    content: `\n## Pikachu ‚ö° Building a Pair Programming Agent at Google AI Tinkerers Toronto\n\nPair programming is magic when it is available. During crunch moments it rarely is. That gap is what our team tried to compress into software.\n\nOver one intense weekend in Toronto, we built **Pikachu**, a real-time, voice and text enabled pair programming agent. We qualified as finalists, learned a ton about what makes agents actually useful on a developer desktop, and shipped something that felt genuinely helpful.\n\n## Why an Agentic Pair Programmer\n\nDevelopers do not just need answers. They need a partner that sees the same screen, tracks the same files, and reacts fast. At Shopify, pairing is part of the culture. In practice, mentors and teammates are not always free at the exact moment a bug melts your brain. Pikachu fills that gap.\n\nOur design goal was simple: a sidekick that sits in the corner of your screen, watches the same context you do, and can help without breaking flow. If you highlight a function, it should understand that selection. If you are missing an import, it should suggest the right diff. If you ask a question out loud, it should respond before your frustration spikes.\n\n## The Hackathon in Three Acts\n\n**Act 1. Scaffolding the loop**  \nWe stood up a FastAPI backend and wired bidirectional WebSocket streaming for audio and text. The target was consistent sub second turn responsibility, not benchmark bragging rights. Streaming shaved perceived latency and made the agent feel present.\n\n**Act 2. Teaching Pikachu to look around**  \nWe added a permissions gated context layer: reading files in the active project, grabbing the current selection, and detecting the IDE state. Security scoped file access was a hard constraint. The rule was clear: only read what the user explicitly allows.\n\n**Act 3. Putting it on the screen**  \nWe built an Electron overlay that is always on top and click through friendly. The UI sits on the edges of your screen with a playful Pikachu animation and thought bubbles. It avoids stealing focus. It injects help when asked or when a high confidence fix is obvious.\n\n## How Pikachu Works\n\n### Core Capabilities\n\n- **Contextual code intelligence**: Reads the current file or a small set of user approved files, summarizes call sites, and tracks the selection.  \n- **Web scale lookup**: Runs live Google searches for docs, RFCs, and error strings, then distills results into short, source linked notes.  \n- **Smart clipboard and prompts**: Generates minimal prompts or diffs and can copy them to the clipboard on request.  \n- **Session memory**: Keeps short lived context in memory so you can jump between tasks without repeating yourself.  \n- **Hands free voice**: Wake word or push to talk, with real time partial transcription and barge in.\n\n### Architecture at a Glance\n\n- **Inference**: Gemini 2.0 Flash Live for ultra low latency conversation and tool output.  \n- **Transport**: Bidirectional WebSockets for both audio and text, with incremental deltas.  \n- **Agent runtime**: Google ADK for tool orchestration and state, plus a slim task router to decide between search, read file, or propose diff.  \n- **Backend**: FastAPI with async streaming endpoints and lightweight rate limiting.  \n- **Desktop UI**: Electron overlay that is always on top, supports click through, and renders subtle borders to show agent focus.  \n- **Security**: Security scoped file reads, no raw disk crawling, explicit user consent for any new path, strict allowlist on network calls.\n\n### The Tooling Loop\n\n1. Detect selection or listen for a request.  \n2. Decide: read file, search the web, propose a code change, or ask a clarifying question.  \n3. Execute tool calls concurrently where safe.  \n4. Stream a concise plan, then a candidate fix as a diff.  \n5. Offer one click actions: copy patch, open file, run command in terminal.\n\n## The Moment It Clicked\n\nLate at night, we highlighted a gnarly TypeScript error in a utility that wrapped fetch. Pikachu read only the file and its imports, found an await in a non async function, surfaced the exact TypeScript diagnostic from docs, and proposed a minimal diff that converted the caller. No multi paragraph essay. Just a plan and the patch. That interaction felt like real pairing.\n\n## What Was Hard\n\n- **Selection awareness**: Mapping GUI selection to semantically relevant AST context is nontrivial. We built a quick parser backed by heuristics that favors stable tokens near the cursor.  \n- **Latency budgets**: Voice plus tools amplifies delays. Streaming everywhere, shrinking prompt templates, and parallelizing search with file reads kept the agent snappy.  \n- **UI restraint**: It is easy to spam the screen. We biased toward quiet defaults and only elevate when confidence is high.\n\n## What Surprised Us\n\n- Small diffs beat long explanations.  \n- Keeping a tiny rolling context window is enough for most micro tasks.  \n- Developers value a clean exit. The best moment is when the agent gets out of the way fast after you accept a fix.\n\n## Impact and Utility\n\nPikachu does not try to replace your IDE or your teammate. It makes pairing accessible at odd hours and lowers the activation energy to ask for help. If you are debugging an API mismatch, pulling in a missing dependency, or trying to remember a flags syntax, the agent is faster than a tab switch and kinder than a Stack Overflow rabbit hole.\n\n## What We Would Build Next\n\n- **Deeper IDE hooks**: First class Cursor and VS Code integrations with native diff apply and test run.  \n- **Stronger safety rails**: Sandboxed commands with preview and auto rollback.  \n- **Knowledge plugins**: Local docs packs for common stacks that work offline.  \n- **Team mode**: Share a short session trace so a human teammate can review what the agent did.\n\n## Team\n\nBuilt with friends from the Toronto AI community: **Ethan Zemelman**, **Aayush Grover**, **Kevin Z**, and me, **Aryan**. Huge thanks to the organizers and mentors who created the space and brought serious energy to the room.\n\n## Closing\n\nI judge projects by a simple question: if I disappeared tomorrow, would this still help someone. Pikachu feels like a yes. It is not perfect. It is already useful.\n\nIf you want to try it or jam on agents for developer workflows, reach out. I am happy to share the repo, walk through the architecture, and keep building.\n\n\nCheck out our demo video here! üëâ https://www.youtube.com/watch?v=njt6bv6RANM\n    `,\n    coverImage: \"/googlehack.jpeg\",\n    isProjectBlog: false,\n    tags: [\"Google AI Tinkerers\", \"Pair Programming\", \"Agentic Programming\", \"FastAPI\", \"WebSocket\", \"Electron\", \"Gemini 2.0 Flash Live\"]\n  }\n];\n\n\n\nexport async function getBlogBySlug(slug: string): Promise<BlogPost | undefined> {\n  return blogPosts.find(post => post.slug === slug);\n}\n\nexport async function getProjectBlog(projectId: number): Promise<BlogPost | undefined> {\n  return blogPosts.find(post => post.isProjectBlog && post.projectId === projectId);\n}\n\nexport async function getAllBlogs(): Promise<BlogPost[]> {\n  return blogPosts;\n}\n\nexport async function getNonProjectBlogs(): Promise<BlogPost[]> {\n  return blogPosts.filter(post => !post.isProjectBlog);\n}\n\nexport async function getProjectBlogs(): Promise<BlogPost[]> {\n  return blogPosts.filter(post => post.isProjectBlog);\n} "],"names":[],"mappings":";;;;;;;;AAaO,MAAM,YAAwB;IACnC;QACE,IAAI;QACJ,OAAO;QACP,MAAM;QACN,MAAM;QACN,SAAS;QACT,SAAS,CAAC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;IAkCV,CAAC;QACD,YAAY;QACZ,eAAe;QACf,WAAW;QACX,MAAM;YAAC;YAAO;YAAgB;YAAmB;SAAU;IAC7D;IACA;QACE,IAAI;QACJ,OAAO;QACP,MAAM;QACN,MAAM;QACN,SAAS;QACT,SAAS,CAAC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;IA0CV,CAAC;QACD,YAAY;QACZ,eAAe;QACf,WAAW;QACX,MAAM;YAAC;YAAQ;YAAc;SAAS;IACxC;IACA;QACE,IAAI;QACJ,OAAO;QACP,MAAM;QACN,MAAM;QACN,SAAS;QACT,SAAS,CAAC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;IAsDV,CAAC;QACD,YAAY;QACZ,eAAe;QACf,WAAW;QACX,MAAM;YAAC;YAAc;YAAY;YAAO;SAAS;IACnD;IACA;QACE,IAAI;QACJ,OAAO;QACP,MAAM;QACN,MAAM;QACN,SAAS;QACT,SAAS,CAAC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;IA6DV,CAAC;QACD,YAAY;QACZ,eAAe;QACf,WAAW;QACX,MAAM;YAAC;YAAU;YAAY;YAAqB;SAAM;IAC1D;IACA;QACE,IAAI;QACJ,OAAO;QACP,MAAM;QACN,MAAM;QACN,SAAS;QACT,SAAS,CAAC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;IA4DV,CAAC;QACD,YAAY;QACZ,eAAe;QACf,WAAW;QACX,MAAM;YAAC;YAAc;YAAU;YAAiB;SAAmB;IACrE;IACA;QACE,IAAI;QACJ,OAAO;QACP,MAAM;QACN,MAAM;QACN,SAAS;QACT,SAAS,CAAC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;IAgEV,CAAC;QACD,YAAY;QACZ,eAAe;QACf,WAAW;QACX,MAAM;YAAC;YAAY;YAAU;SAAU;IACzC;IACF;QACE,IAAI;QACJ,OAAO;QACP,MAAM;QACN,MAAM;QACN,SAAS;QACT,SAAS,CAAC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;EA4FV,CAAC;QACD,YAAY;QACZ,eAAe;QACf,WAAW;QACX,MAAM;YAAC;YAAW;YAAS;YAAY;YAAY;YAAwB;SAAiB;IAC5F;IACA;QACE,IAAI;QACJ,OAAO;QACP,MAAM;QACN,MAAM;QACN,SAAS;QACT,SAAS,CAAC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;IA0FV,CAAC;QACD,YAAY;QACZ,eAAe;QACf,MAAM;YAAC;YAAuB;YAAoB;YAAuB;YAAW;YAAa;YAAY;SAAwB;IACvI;CACD;AAIM,eAAe,cAAc,IAAY;IAC9C,OAAO,UAAU,IAAI,CAAC,CAAA,OAAQ,KAAK,IAAI,KAAK;AAC9C;AAEO,eAAe,eAAe,SAAiB;IACpD,OAAO,UAAU,IAAI,CAAC,CAAA,OAAQ,KAAK,aAAa,IAAI,KAAK,SAAS,KAAK;AACzE;AAEO,eAAe;IACpB,OAAO;AACT;AAEO,eAAe;IACpB,OAAO,UAAU,MAAM,CAAC,CAAA,OAAQ,CAAC,KAAK,aAAa;AACrD;AAEO,eAAe;IACpB,OAAO,UAAU,MAAM,CAAC,CAAA,OAAQ,KAAK,aAAa;AACpD"}},
    {"offset": {"line": 667, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 673, "column": 0}, "map": {"version":3,"sources":["file:///Users/aryan/projects/personalwebsite/app/blogs/page.tsx"],"sourcesContent":["import Link from 'next/link';\nimport Image from 'next/image';\nimport { getAllBlogs } from '@/data/blogs';\n\nexport const metadata = {\n  title: 'Blogs | Aryan Gupta',\n  description: 'Blog posts about technology, projects, and more by Aryan Gupta',\n};\n\nexport default async function BlogsPage() {\n  const blogs = await getAllBlogs();\n  \n  return (\n    <main className=\"min-h-screen bg-black text-white\">\n      <div className=\"max-w-5xl mx-auto px-4 py-28 sm:px-6 lg:px-8\">\n        <h1 className=\"text-4xl font-bold mb-8 tracking-tight\">Blog</h1>\n        \n        <div className=\"grid gap-10\">\n          {blogs.map((blog) => (\n            <article key={blog.id} className=\"group\">\n              <Link href={`/blogs/${blog.slug}`} className=\"block\">\n                <div className=\"grid md:grid-cols-4 gap-6\">\n                  {blog.coverImage && (\n                    <div className=\"md:col-span-1\">\n                      <div className=\"aspect-w-16 aspect-h-9 relative overflow-hidden rounded-lg\">\n                        <Image\n                          src={blog.coverImage}\n                          alt={blog.title}\n                          fill\n                          className=\"object-cover transition-transform duration-300 group-hover:scale-105\"\n                        />\n                      </div>\n                    </div>\n                  )}\n                  \n                  <div className={blog.coverImage ? \"md:col-span-3\" : \"md:col-span-4\"}>\n                    <div className=\"flex items-center text-sm text-gray-400 mb-2\">\n                      <time dateTime={blog.date}>{new Date(blog.date).toLocaleDateString('en-US', {\n                        year: 'numeric',\n                        month: 'long',\n                        day: 'numeric'\n                      })}</time>\n                      \n                      {blog.isProjectBlog && (\n                        <>\n                          <span className=\"mx-2\">‚Ä¢</span>\n                          <span className=\"text-blue-400\">Project Blog</span>\n                        </>\n                      )}\n                    </div>\n                    \n                    <h2 className=\"text-2xl font-semibold mb-2 group-hover:text-blue-400 transition-colors\">\n                      {blog.title}\n                    </h2>\n                    \n                    <p className=\"text-gray-300 mb-4\">{blog.summary}</p>\n                    \n                    <div className=\"flex flex-wrap gap-2\">\n                      {blog.tags.map((tag) => (\n                        <span key={tag} className=\"px-2 py-1 text-xs bg-gray-800 rounded-full text-gray-300\">\n                          {tag}\n                        </span>\n                      ))}\n                    </div>\n                  </div>\n                </div>\n              </Link>\n            </article>\n          ))}\n        </div>\n      </div>\n    </main>\n  );\n} "],"names":[],"mappings":";;;;;AAAA;AACA;AACA;;;;;AAEO,MAAM,WAAW;IACtB,OAAO;IACP,aAAa;AACf;AAEe,eAAe;IAC5B,MAAM,QAAQ,MAAM,CAAA,GAAA,oHAAA,CAAA,cAAW,AAAD;IAE9B,qBACE,8OAAC;QAAK,WAAU;kBACd,cAAA,8OAAC;YAAI,WAAU;;8BACb,8OAAC;oBAAG,WAAU;8BAAyC;;;;;;8BAEvD,8OAAC;oBAAI,WAAU;8BACZ,MAAM,GAAG,CAAC,CAAC,qBACV,8OAAC;4BAAsB,WAAU;sCAC/B,cAAA,8OAAC,4JAAA,CAAA,UAAI;gCAAC,MAAM,CAAC,OAAO,EAAE,KAAK,IAAI,EAAE;gCAAE,WAAU;0CAC3C,cAAA,8OAAC;oCAAI,WAAU;;wCACZ,KAAK,UAAU,kBACd,8OAAC;4CAAI,WAAU;sDACb,cAAA,8OAAC;gDAAI,WAAU;0DACb,cAAA,8OAAC,6HAAA,CAAA,UAAK;oDACJ,KAAK,KAAK,UAAU;oDACpB,KAAK,KAAK,KAAK;oDACf,IAAI;oDACJ,WAAU;;;;;;;;;;;;;;;;sDAMlB,8OAAC;4CAAI,WAAW,KAAK,UAAU,GAAG,kBAAkB;;8DAClD,8OAAC;oDAAI,WAAU;;sEACb,8OAAC;4DAAK,UAAU,KAAK,IAAI;sEAAG,IAAI,KAAK,KAAK,IAAI,EAAE,kBAAkB,CAAC,SAAS;gEAC1E,MAAM;gEACN,OAAO;gEACP,KAAK;4DACP;;;;;;wDAEC,KAAK,aAAa,kBACjB;;8EACE,8OAAC;oEAAK,WAAU;8EAAO;;;;;;8EACvB,8OAAC;oEAAK,WAAU;8EAAgB;;;;;;;;;;;;;;8DAKtC,8OAAC;oDAAG,WAAU;8DACX,KAAK,KAAK;;;;;;8DAGb,8OAAC;oDAAE,WAAU;8DAAsB,KAAK,OAAO;;;;;;8DAE/C,8OAAC;oDAAI,WAAU;8DACZ,KAAK,IAAI,CAAC,GAAG,CAAC,CAAC,oBACd,8OAAC;4DAAe,WAAU;sEACvB;2DADQ;;;;;;;;;;;;;;;;;;;;;;;;;;;2BAxCT,KAAK,EAAE;;;;;;;;;;;;;;;;;;;;;AAsDjC"}},
    {"offset": {"line": 852, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 863, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":""}},
    {"offset": {"line": 863, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}}]
}